**Task: Detection Transference	Family: type	Language: en**


| model                     | train   | test   |   generated-precision |   generated-recall |   generated-f1-score |   human-precision |   human-recall |   human-f1-score |   accuracy |   macro avg-precision |   macro avg-recall |   macro avg-f1-score |
|---------------------------|---------|--------|-----------------------|--------------------|----------------------|-------------------|----------------|------------------|------------|-----------------------|--------------------|----------------------|
| bigscience-bloom-560m     | bloom   | bloom  |                 95.38 |              92.08 |                93.70 |             92.34 |          95.54 |            93.92 |      93.81 |                 93.86 |              93.81 |                93.81 |
| bigscience-bloom-560m     | bloom   | gpt    |                 90.01 |              44.24 |                59.32 |             63.04 |          95.09 |            75.81 |      69.66 |                 76.52 |              69.66 |                67.57 |
| bigscience-bloom-560m     | gpt     | bloom  |                 89.03 |              60.69 |                72.17 |             70.18 |          92.52 |            79.82 |      76.60 |                 79.60 |              76.60 |                75.99 |
| bigscience-bloom-560m     | gpt     | gpt    |                 90.36 |              88.86 |                89.61 |             89.04 |          90.52 |            89.78 |      89.69 |                 89.70 |              89.69 |                89.69 |
| microsoft-deberta-v3-base | bloom   | bloom  |                 91.48 |              99.26 |                95.21 |             99.19 |          90.75 |            94.79 |      95.01 |                 95.34 |              95.01 |                95.00 |
| microsoft-deberta-v3-base | bloom   | gpt    |                 86.16 |              68.28 |                76.19 |             73.73 |          89.03 |            80.66 |      78.66 |                 79.95 |              78.66 |                78.43 |
| microsoft-deberta-v3-base | gpt     | bloom  |                 84.06 |              87.21 |                85.61 |             86.72 |          83.46 |            85.05 |      85.34 |                 85.39 |              85.34 |                85.33 |
| microsoft-deberta-v3-base | gpt     | gpt    |                 82.72 |              98.55 |                89.94 |             98.20 |          79.42 |            87.82 |      88.98 |                 90.46 |              88.98 |                88.88 |
| xlm-roberta-base          | bloom   | bloom  |                 87.60 |              99.41 |                93.13 |             99.32 |          85.92 |            92.14 |      92.67 |                 93.46 |              92.67 |                92.63 |
| xlm-roberta-base          | bloom   | gpt    |                 82.73 |              76.06 |                79.26 |             77.85 |          84.12 |            80.86 |      80.09 |                 80.29 |              80.09 |                80.06 |
| xlm-roberta-base          | gpt     | bloom  |                 81.58 |              83.24 |                82.40 |             82.89 |          81.21 |            82.04 |      82.22 |                 82.24 |              82.22 |                82.22 |
| xlm-roberta-base          | gpt     | gpt    |                 82.13 |              98.37 |                89.52 |             97.97 |          78.59 |            87.22 |      88.48 |                 90.05 |              88.48 |                88.37 |



**Task: Detection Transference	Family: type	Language: es**


| model                          | train   | test   |   generated-precision |   generated-recall |   generated-f1-score |   human-precision |   human-recall |   human-f1-score |   accuracy |   macro avg-precision |   macro avg-recall |   macro avg-f1-score |
|--------------------------------|---------|--------|-----------------------|--------------------|----------------------|-------------------|----------------|------------------|------------|-----------------------|--------------------|----------------------|
| PlanTL-GOB-ES-roberta-base-bne | bloom   | bloom  |                 96.83 |              95.68 |                96.25 |             95.73 |          96.86 |            96.29 |      96.27 |                 96.28 |              96.27 |                96.27 |
| PlanTL-GOB-ES-roberta-base-bne | bloom   | gpt    |                 90.98 |              43.60 |                58.95 |             62.91 |          95.67 |            75.91 |      69.64 |                 76.94 |              69.64 |                67.43 |
| PlanTL-GOB-ES-roberta-base-bne | gpt     | bloom  |                 92.43 |              41.11 |                56.91 |             62.13 |          96.63 |            75.64 |      68.87 |                 77.28 |              68.87 |                66.27 |
| PlanTL-GOB-ES-roberta-base-bne | gpt     | gpt    |                 95.04 |              94.91 |                94.97 |             94.91 |          95.05 |            94.98 |      94.98 |                 94.98 |              94.98 |                94.98 |
| bigscience-bloom-560m          | bloom   | bloom  |                 87.07 |              89.06 |                88.05 |             88.81 |          86.77 |            87.78 |      87.92 |                 87.94 |              87.92 |                87.91 |
| bigscience-bloom-560m          | bloom   | gpt    |                 77.45 |              56.05 |                65.03 |             65.56 |          83.68 |            73.52 |      69.86 |                 71.51 |              69.86 |                69.28 |
| bigscience-bloom-560m          | gpt     | bloom  |                 88.84 |              37.44 |                52.68 |             60.37 |          95.30 |            73.91 |      66.37 |                 74.60 |              66.37 |                63.30 |
| bigscience-bloom-560m          | gpt     | gpt    |                 92.94 |              88.56 |                90.69 |             89.07 |          93.27 |            91.12 |      90.91 |                 91.00 |              90.91 |                90.91 |
| xlm-roberta-base               | bloom   | bloom  |                 85.47 |              99.01 |                91.74 |             98.82 |          83.17 |            90.32 |      91.09 |                 92.15 |              91.09 |                91.03 |
| xlm-roberta-base               | bloom   | gpt    |                 77.80 |              70.42 |                73.93 |             72.99 |          79.91 |            76.29 |      75.17 |                 75.39 |              75.17 |                75.11 |
| xlm-roberta-base               | gpt     | bloom  |                 81.41 |              62.29 |                70.58 |             69.46 |          85.77 |            76.76 |      74.03 |                 75.44 |              74.03 |                73.67 |
| xlm-roberta-base               | gpt     | gpt    |                 84.55 |              98.85 |                91.14 |             98.61 |          81.93 |            89.50 |      90.39 |                 91.58 |              90.39 |                90.32 |



**Task: Detection transference	Family: params	Language: en**


| model                     | train   | test   |   generated-precision |   generated-recall |   generated-f1-score |   human-precision |   human-recall |   human-f1-score |   accuracy |   macro avg-precision |   macro avg-recall |   macro avg-f1-score |
|---------------------------|---------|--------|-----------------------|--------------------|----------------------|-------------------|----------------|------------------|------------|-----------------------|--------------------|----------------------|
| bigscience-bloom-560m     | 175b    | 175b   |                 94.12 |              89.07 |                91.52 |             89.63 |          94.43 |            91.97 |      91.75 |                 91.87 |              91.75 |                91.75 |
| bigscience-bloom-560m     | 175b    | 1b     |                 87.59 |              41.30 |                56.14 |             61.60 |          94.15 |            74.47 |      67.73 |                 74.59 |              67.73 |                65.30 |
| bigscience-bloom-560m     | 175b    | 7b     |                 90.14 |              50.18 |                64.47 |             65.48 |          94.51 |            77.36 |      72.35 |                 77.81 |              72.35 |                70.92 |
| bigscience-bloom-560m     | 1b      | 175b   |                 97.04 |              62.96 |                76.37 |             72.58 |          98.08 |            83.43 |      80.52 |                 84.81 |              80.52 |                79.90 |
| bigscience-bloom-560m     | 1b      | 1b     |                 91.26 |              88.18 |                89.69 |             88.57 |          91.55 |            90.04 |      89.87 |                 89.91 |              89.87 |                89.86 |
| bigscience-bloom-560m     | 1b      | 7b     |                 89.28 |              81.51 |                85.22 |             82.99 |          90.21 |            86.45 |      85.86 |                 86.14 |              85.86 |                85.84 |
| bigscience-bloom-560m     | 7b      | 175b   |                 96.92 |              66.90 |                79.16 |             74.73 |          97.87 |            84.75 |      82.39 |                 85.83 |              82.39 |                81.96 |
| bigscience-bloom-560m     | 7b      | 1b     |                 90.40 |              84.76 |                87.49 |             85.65 |          91.00 |            88.25 |      87.88 |                 88.03 |              87.88 |                87.87 |
| bigscience-bloom-560m     | 7b      | 7b     |                 88.37 |              83.79 |                86.02 |             84.59 |          88.97 |            86.72 |      86.38 |                 86.48 |              86.38 |                86.37 |
| microsoft-deberta-v3-base | 175b    | 175b   |                 86.75 |              99.39 |                92.64 |             99.29 |          84.82 |            91.48 |      92.11 |                 93.02 |              92.11 |                92.06 |
| microsoft-deberta-v3-base | 175b    | 1b     |                 79.04 |              62.45 |                69.77 |             68.96 |          83.43 |            75.51 |      72.94 |                 74.00 |              72.94 |                72.64 |
| microsoft-deberta-v3-base | 175b    | 7b     |                 82.49 |              80.27 |                81.36 |             80.79 |          82.96 |            81.86 |      81.62 |                 81.64 |              81.62 |                81.61 |
| microsoft-deberta-v3-base | 1b      | 175b   |                 98.91 |              82.39 |                89.90 |             84.91 |          99.09 |            91.45 |      90.74 |                 91.91 |              90.74 |                90.67 |
| microsoft-deberta-v3-base | 1b      | 1b     |                 89.82 |              97.40 |                93.46 |             97.17 |          88.96 |            92.88 |      93.18 |                 93.49 |              93.18 |                93.17 |
| microsoft-deberta-v3-base | 1b      | 7b     |                 87.92 |              96.12 |                91.84 |             95.72 |          86.79 |            91.04 |      91.46 |                 91.82 |              91.46 |                91.44 |
| microsoft-deberta-v3-base | 7b      | 175b   |                 90.41 |              94.43 |                92.38 |             94.17 |          89.98 |            92.03 |      92.21 |                 92.29 |              92.21 |                92.20 |
| microsoft-deberta-v3-base | 7b      | 1b     |                 80.86 |              98.23 |                88.71 |             97.75 |          76.75 |            85.99 |      87.49 |                 89.31 |              87.49 |                87.35 |
| microsoft-deberta-v3-base | 7b      | 7b     |                 77.84 |              99.12 |                87.20 |             98.79 |          71.78 |            83.14 |      85.45 |                 88.31 |              85.45 |                85.17 |
| xlm-roberta-base          | 175b    | 175b   |                 83.14 |              99.29 |                90.50 |             99.12 |          79.86 |            88.45 |      89.57 |                 91.13 |              89.57 |                89.48 |
| xlm-roberta-base          | 175b    | 1b     |                 77.05 |              69.91 |                73.31 |             72.46 |          79.18 |            75.67 |      74.54 |                 74.76 |              74.54 |                74.49 |
| xlm-roberta-base          | 175b    | 7b     |                 79.82 |              82.96 |                81.36 |             82.26 |          79.03 |            80.61 |      80.99 |                 81.04 |              80.99 |                80.99 |
| xlm-roberta-base          | 1b      | 175b   |                 89.86 |              92.41 |                91.12 |             92.19 |          89.57 |            90.86 |      90.99 |                 91.02 |              90.99 |                90.99 |
| xlm-roberta-base          | 1b      | 1b     |                 81.99 |              98.01 |                89.29 |             97.53 |          78.46 |            86.96 |      88.24 |                 89.76 |              88.24 |                88.13 |
| xlm-roberta-base          | 1b      | 7b     |                 79.55 |              98.14 |                87.87 |             97.57 |          74.78 |            84.67 |      86.46 |                 88.56 |              86.46 |                86.27 |
| xlm-roberta-base          | 7b      | 175b   |                 85.58 |              94.94 |                90.02 |             94.32 |          84.01 |            88.87 |      89.47 |                 89.95 |              89.47 |                89.44 |
| xlm-roberta-base          | 7b      | 1b     |                 77.77 |              98.51 |                86.92 |             97.97 |          71.84 |            82.89 |      85.17 |                 87.87 |              85.17 |                84.91 |
| xlm-roberta-base          | 7b      | 7b     |                 74.83 |              99.17 |                85.30 |             98.77 |          66.65 |            79.59 |      82.91 |                 86.80 |              82.91 |                82.45 |



**Task: Detection Transference	Family: params	Language: es**


| model                          | train   | test   |   generated-precision |   generated-recall |   generated-f1-score |   human-precision |   human-recall |   human-f1-score |   accuracy |   macro avg-precision |   macro avg-recall |   macro avg-f1-score |
|--------------------------------|---------|--------|-----------------------|--------------------|----------------------|-------------------|----------------|------------------|------------|-----------------------|--------------------|----------------------|
| PlanTL-GOB-ES-roberta-base-bne | 175b    | 175b   |                 96.39 |              96.18 |                96.29 |             96.19 |          96.40 |            96.30 |      96.29 |                 96.29 |              96.29 |                96.29 |
| PlanTL-GOB-ES-roberta-base-bne | 175b    | 1b     |                 89.16 |              38.49 |                53.77 |             60.78 |          95.32 |            74.23 |      66.91 |                 74.97 |              66.91 |                64.00 |
| PlanTL-GOB-ES-roberta-base-bne | 175b    | 7b     |                 90.18 |              49.79 |                64.16 |             65.32 |          94.58 |            77.27 |      72.18 |                 77.75 |              72.18 |                70.71 |
| PlanTL-GOB-ES-roberta-base-bne | 1b      | 175b   |                100.00 |              71.43 |                83.33 |             77.78 |         100.00 |            87.50 |      85.71 |                 88.89 |              85.71 |                85.42 |
| PlanTL-GOB-ES-roberta-base-bne | 1b      | 1b     |                 95.16 |              93.12 |                94.13 |             93.26 |          95.26 |            94.25 |      94.19 |                 94.21 |              94.19 |                94.19 |
| PlanTL-GOB-ES-roberta-base-bne | 1b      | 7b     |                 94.50 |              87.57 |                90.90 |             88.42 |          94.90 |            91.54 |      91.23 |                 91.46 |              91.23 |                91.22 |
| PlanTL-GOB-ES-roberta-base-bne | 7b      | 175b   |                100.00 |              87.68 |                93.43 |             89.03 |         100.00 |            94.20 |      93.84 |                 94.51 |              93.84 |                93.82 |
| PlanTL-GOB-ES-roberta-base-bne | 7b      | 1b     |                 93.19 |              90.36 |                91.75 |             90.65 |          93.39 |            92.00 |      91.88 |                 91.92 |              91.88 |                91.88 |
| PlanTL-GOB-ES-roberta-base-bne | 7b      | 7b     |                 92.65 |              92.40 |                92.52 |             92.42 |          92.67 |            92.54 |      92.53 |                 92.53 |              92.53 |                92.53 |
| bigscience-bloom-560m          | 175b    | 175b   |                 96.07 |              90.62 |                93.27 |             91.12 |          96.29 |            93.64 |      93.46 |                 93.60 |              93.46 |                93.45 |
| bigscience-bloom-560m          | 175b    | 1b     |                 85.97 |              37.11 |                51.85 |             59.90 |          93.94 |            73.16 |      65.53 |                 72.94 |              65.53 |                62.50 |
| bigscience-bloom-560m          | 175b    | 7b     |                 87.30 |              40.54 |                55.37 |             61.28 |          94.10 |            74.22 |      67.32 |                 74.29 |              67.32 |                64.80 |
| bigscience-bloom-560m          | 1b      | 175b   |                 97.15 |              78.08 |                86.58 |             81.68 |          97.71 |            88.98 |      87.90 |                 89.41 |              87.90 |                87.78 |
| bigscience-bloom-560m          | 1b      | 1b     |                 88.45 |              92.79 |                90.57 |             92.41 |          87.89 |            90.09 |      90.34 |                 90.43 |              90.34 |                90.33 |
| bigscience-bloom-560m          | 1b      | 7b     |                 86.99 |              86.34 |                86.67 |             86.45 |          87.09 |            86.77 |      86.72 |                 86.72 |              86.72 |                86.72 |
| bigscience-bloom-560m          | 7b      | 175b   |                 98.40 |              80.37 |                88.48 |             83.41 |          98.69 |            90.41 |      89.53 |                 90.90 |              89.53 |                89.44 |
| bigscience-bloom-560m          | 7b      | 1b     |                 89.25 |              86.84 |                88.03 |             87.18 |          89.54 |            88.35 |      88.19 |                 88.22 |              88.19 |                88.19 |
| bigscience-bloom-560m          | 7b      | 7b     |                 88.28 |              86.82 |                87.54 |             87.04 |          88.47 |            87.75 |      87.65 |                 87.66 |              87.65 |                87.65 |
| xlm-roberta-base               | 175b    | 175b   |                 83.50 |              99.35 |                90.74 |             99.19 |          80.37 |            88.80 |      89.86 |                 91.35 |              89.86 |                89.77 |
| xlm-roberta-base               | 175b    | 1b     |                 76.09 |              70.98 |                73.45 |             72.81 |          77.70 |            75.17 |      74.34 |                 74.45 |              74.34 |                74.31 |
| xlm-roberta-base               | 175b    | 7b     |                 77.95 |              82.09 |                79.97 |             81.09 |          76.78 |            78.88 |      79.44 |                 79.52 |              79.44 |                79.42 |
| xlm-roberta-base               | 1b      | 175b   |                 89.57 |              93.68 |                91.58 |             93.37 |          89.09 |            91.18 |      91.38 |                 91.47 |              91.38 |                91.38 |
| xlm-roberta-base               | 1b      | 1b     |                 79.01 |              98.90 |                87.85 |             98.53 |          73.73 |            84.35 |      86.32 |                 88.77 |              86.32 |                86.10 |
| xlm-roberta-base               | 1b      | 7b     |                 77.63 |              98.09 |                86.67 |             97.40 |          71.73 |            82.62 |      84.91 |                 87.52 |              84.91 |                84.64 |
| xlm-roberta-base               | 7b      | 175b   |                 84.67 |              96.40 |                90.16 |             95.82 |          82.55 |            88.69 |      89.48 |                 90.25 |              89.48 |                89.43 |
| xlm-roberta-base               | 7b      | 1b     |                 75.37 |              99.06 |                85.61 |             98.63 |          67.62 |            80.24 |      83.34 |                 87.00 |              83.34 |                82.92 |
| xlm-roberta-base               | 7b      | 7b     |                 73.93 |              98.99 |                84.64 |             98.47 |          65.09 |            78.37 |      82.04 |                 86.20 |              82.04 |                81.51 |



**Task: Attribution	Family: type	Language: en**


| model                      |   bloom-precision |   bloom-recall |   bloom-f1-score |   gpt-precision |   gpt-recall |   gpt-f1-score |   accuracy |   macro avg-precision |   macro avg-recall |   macro avg-f1-score |
|---------------------------|-------------------|----------------|------------------|-----------------|--------------|----------------|------------|-----------------------|--------------------|----------------------|
| bigscience-bloom-560m     |             91.12 |          89.98 |            90.55 |           90.70 |        91.77 |          91.23 |      90.90 |                 90.91 |              90.87 |                90.89 |
| microsoft-deberta-v3-base |             94.57 |          93.63 |            94.09 |           94.07 |        94.95 |          94.51 |      94.31 |                 94.32 |              94.29 |                94.30 |
| xlm-roberta-base          |             91.11 |          97.02 |            93.97 |           97.02 |        91.11 |          93.97 |      93.97 |                 94.06 |              94.06 |                93.97 |



**Task: Attribution Family: type	Language: es**


| model                           |   bloom-precision |   bloom-recall |   bloom-f1-score |   gpt-precision |   gpt-recall |   gpt-f1-score |   accuracy |   macro avg-precision |   macro avg-recall |   macro avg-f1-score |
|--------------------------------|-------------------|----------------|------------------|-----------------|--------------|----------------|------------|-----------------------|--------------------|----------------------|
| PlanTL-GOB-ES-roberta-base-bne |             94.93 |          94.61 |            94.77 |           95.10 |        95.40 |          95.25 |      95.02 |                 95.02 |              95.00 |                95.01 |
| bigscience-bloom-560m          |             94.11 |          88.57 |            91.25 |           90.10 |        94.94 |          92.46 |      91.90 |                 92.11 |              91.75 |                91.86 |
| xlm-roberta-base               |             94.52 |          95.68 |            95.10 |           96.01 |        94.94 |          95.48 |      95.29 |                 95.27 |              95.31 |                95.29 |



**Task: Attribution	Family: params	Language: en**


| model                      |   approx. 1b-precision |   approx. 1b-recall |   approx. 1b-f1-score |   approx. 7b-precision |   approx. 7b-recall |   approx. 7b-f1-score |   accuracy |   macro avg-precision |   macro avg-recall |   macro avg-f1-score |
|---------------------------|------------------------|---------------------|-----------------------|------------------------|---------------------|-----------------------|------------|-----------------------|--------------------|----------------------|
| bigscience-bloom-560m     |                  57.54 |               55.44 |                 56.47 |                  59.59 |               61.63 |                 60.59 |      58.63 |                 58.56 |              58.53 |                58.53 |
| microsoft-deberta-v3-base |                  68.01 |               66.32 |                 67.15 |                  69.13 |               70.74 |                 69.93 |      68.60 |                 68.57 |              68.53 |                68.54 |
| xlm-roberta-base          |                  48.40 |              100.00 |                 65.23 |                   0.00 |                0.00 |                  0.00 |      48.40 |                 24.20 |              50.00 |                32.61 |



**Task: Attribution	Family: params	Language: es**


| model                           |   approx. 1b-precision |   approx. 1b-recall |   approx. 1b-f1-score |   approx. 7b-precision |   approx. 7b-recall |   approx. 7b-f1-score |   accuracy |   macro avg-precision |   macro avg-recall |   macro avg-f1-score |
|--------------------------------|------------------------|---------------------|-----------------------|------------------------|---------------------|-----------------------|------------|-----------------------|--------------------|----------------------|
| PlanTL-GOB-ES-roberta-base-bne |                  71.66 |               69.22 |                 70.42 |                  71.24 |               73.59 |                 72.40 |      71.44 |                 71.45 |              71.40 |                71.41 |
| bigscience-bloom-560m          |                  57.32 |               62.72 |                 59.90 |                  60.43 |               54.94 |                 57.56 |      58.76 |                 58.88 |              58.83 |                58.73 |
| xlm-roberta-base               |                  49.11 |              100.00 |                 65.87 |                   0.00 |                0.00 |                  0.00 |      49.11 |                 24.55 |              50.00 |                32.93 |


